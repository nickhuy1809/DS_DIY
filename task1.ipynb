{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in d:\\downloads\\python\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in d:\\downloads\\python\\lib\\site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: requests~=2.32.0 in d:\\downloads\\python\\lib\\site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in d:\\downloads\\python\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\downloads\\python\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\downloads\\python\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\downloads\\python\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\downloads\\python\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"arxiv\").setLevel(logging.ERROR)   \n",
    "import arxiv\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of digits in student IDs: 63\n",
      "k value: 13\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "student_ids = ['23127130', '23127051', '23127107']\n",
    "for id in student_ids:\n",
    "    for number in id:\n",
    "        num += int(number)\n",
    "        \n",
    "print(\"Sum of digits in student IDs:\", num)\n",
    "k = num % 50\n",
    "print(\"k value:\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(number:int, k:int) -> bool:\n",
    "    sum = 0\n",
    "    while number > 0:\n",
    "        sum += number % 10\n",
    "        number = int(number / 10)\n",
    "    print(sum)\n",
    "    if (sum % 50) == k:\n",
    "        return True \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_month = 3\n",
    "start_year = 2023\n",
    "start_ID = 7856\n",
    "end_month = 4\n",
    "end_year = 2023\n",
    "end_ID = 4606\n",
    "\n",
    "\n",
    "def is_valid(number:int, k:int) -> bool:\n",
    "    sum = 0\n",
    "    while number > 0:\n",
    "        sum += number % 10\n",
    "        number = int(number / 10)\n",
    "    \n",
    "    if (sum % 50) == k:\n",
    "        return True \n",
    "    return False\n",
    "\n",
    "def get_ID(month, year, number):\n",
    "    \"\"\"Return arXiv ID in YYMM.NNNNN format.\"\"\"\n",
    "    return f\"{year % 100:02d}{month:02d}.{number:05d}\"\n",
    "\n",
    "def id_exists(paper_id):\n",
    "    \"\"\"Check if a specific arXiv ID exists.\"\"\"\n",
    "    search = arxiv.Search(id_list=[paper_id])\n",
    "    client = arxiv.Client(page_size=1, delay_seconds=0.2)\n",
    "    try:\n",
    "        next(client.results(search))\n",
    "        return True\n",
    "    except StopIteration:\n",
    "        return False\n",
    "    except Exception:\n",
    "        # Network or parsing error â€” assume not found for safety\n",
    "        return False\n",
    "\n",
    "def find_first_id(year, month):\n",
    "    \"\"\"Find the first valid arXiv ID of a given month using exponential + binary search.\"\"\"\n",
    "    low, high = 1, 1\n",
    "    # Exponential search upward until we find a valid ID\n",
    "    while not id_exists(get_ID(month, year, high)):\n",
    "        high *= 2\n",
    "        if high > 99999:\n",
    "            return None  # No valid papers this month\n",
    "\n",
    "    # Now binary search between low and high to find the *first* valid ID\n",
    "    while low + 1 < high:\n",
    "        mid = (low + high) // 2\n",
    "        if id_exists(get_ID(month, year, mid)):\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid\n",
    "    return high\n",
    "\n",
    "def find_last_id(year, month):\n",
    "    \"\"\"Find the last valid arXiv ID of a given month.\"\"\"\n",
    "    low, high = 1, 1\n",
    "    # Exponential search upward until we find a missing ID\n",
    "    while id_exists(get_ID(month, year, high)):\n",
    "        high *= 2\n",
    "        if high > 99999:\n",
    "            return 99999\n",
    "    low = high // 2\n",
    "    # Binary search for the last existing ID\n",
    "    while low + 1 < high:\n",
    "        mid = (low + high) // 2\n",
    "        if id_exists(get_ID(month, year, mid)):\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "    return low\n",
    "\n",
    "def get_IDs_month(month, year, start_number, end_number):\n",
    "    \"\"\"Get all valid arXiv IDs in a given month.\"\"\"\n",
    "    id_month = []\n",
    "    \n",
    "    for i in range(start_number, end_number + 1):\n",
    "        number = i\n",
    "        if is_valid(number, k) == True:\n",
    "            id_month.append(get_ID(month, year, i)) \n",
    "    return id_month\n",
    "\n",
    "def get_IDs_All(start_month, start_year, start_ID, end_month, end_year, end_ID):\n",
    "    \"\"\"Get all valid arXiv IDs in the given range.\"\"\"\n",
    "    ids = []\n",
    "    y, m = start_year, start_month\n",
    "    n_start = start_ID\n",
    "    n_end = None\n",
    "    \n",
    "    while True:\n",
    "        if y == end_year and m == end_month:\n",
    "            n_end = end_ID\n",
    "        else:\n",
    "            n_end = find_last_id(y, m)\n",
    "            if n_end is None:\n",
    "                n_end = 0  # No papers this month\n",
    "\n",
    "        if n_start <= n_end:\n",
    "            ids.extend(get_IDs_month(m, y, n_start, n_end))\n",
    "\n",
    "        if y == end_year and m == end_month:\n",
    "            break\n",
    "        m += 1\n",
    "        if m > 12:\n",
    "            m, y = 1, y + 1\n",
    "        n_start = find_first_id(y, m)  # reset numbering\n",
    "\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = get_IDs_All(start_month, start_year, start_ID, end_month, end_year, end_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_yymm_id(base_id: str) -> str:\n",
    "    \"\"\"'2303.07856' -> '2303-07856'\"\"\"\n",
    "    return base_id.replace('.', '-')\n",
    "\n",
    "def get_paper_references(arxiv_id, delay=2):\n",
    "    \"\"\"\n",
    "    Fetch references for a paper from Semantic Scholar API.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_id: arXiv ID (format: YYMM.NNNNN or YYMM.NNNNNvN)\n",
    "        retry: number of retry attempts\n",
    "        delay: delay between retries in seconds\n",
    "    \n",
    "    Returns:\n",
    "        list: List of references with detailed information\n",
    "    \"\"\"\n",
    "    # Clean arxiv_id (remove version suffix if present)\n",
    "    clean_id = re.sub(r'v\\d+$', '', arxiv_id)\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/arXiv:{clean_id}\"\n",
    "    params = {\n",
    "        \"fields\": \"references,references.title,references.authors,references.year,references.venue,references.externalIds,references.publicationDate, references.abstract, references.publicationVenue, references.referenceCount, references.influentialCitationCount, references.journal, references.embedding, references.fieldsOfStudy, references.publicationTypes, references.isOpenAccess, references.s2FieldsOfStudy, references.citationCount, references.corpusId\"\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                return data.get(\"references\", [])\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"  Rate limit hit. Waiting {delay}s before retry...\")\n",
    "                time.sleep(delay)\n",
    "            elif response.status_code == 404:\n",
    "                print(f\"  Paper {arxiv_id} not found in Semantic Scholar\")\n",
    "                return []\n",
    "            else:\n",
    "                print(f\"  API returned status {response.status_code}, retrying in {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  Request error: {e}, retrying in {delay}s...\")\n",
    "            time.sleep(delay)\n",
    " \n",
    "\n",
    "def convert_to_references_dict(references):\n",
    "    \"\"\"\n",
    "    Convert Semantic Scholar references to the required format:\n",
    "    Dictionary with arXiv IDs as keys (in \"yyyymm-id\" format) for papers with arXiv IDs.\n",
    "    For papers without arXiv IDs, use DOI or generate a unique key.\n",
    "    \n",
    "    Args:\n",
    "        references: List of references from Semantic Scholar API\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with paper IDs as keys and metadata as values\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    non_arxiv_counter = 1\n",
    "    \n",
    "    for ref in references:\n",
    "        # The reference data is directly in ref, not under \"citedPaper\"\n",
    "        \n",
    "        # Skip if reference is None or empty\n",
    "        if not ref:\n",
    "            continue\n",
    "        \n",
    "        # Extract external IDs (may be None)\n",
    "        external_ids = ref.get(\"externalIds\", {})\n",
    "        if external_ids is None:\n",
    "            external_ids = {}\n",
    "        \n",
    "        arxiv_id = external_ids.get(\"ArXiv\", \"\")\n",
    "        doi = external_ids.get(\"DOI\", \"\")\n",
    "        # Only keep references that have arXiv_id\n",
    "        if not arxiv_id:\n",
    "            continue\n",
    "        \n",
    "        # Determine the key for this reference\n",
    "        if arxiv_id:\n",
    "            # Use arXiv ID in yyyymm-id format\n",
    "            key = format_yymm_id(arxiv_id)\n",
    "        elif doi:\n",
    "            # Use DOI as key (sanitize it)\n",
    "            key = f\"doi:{doi.replace('/', '_')}\"\n",
    "        else:\n",
    "            # Generate a unique key for papers without arXiv ID or DOI\n",
    "            title = ref.get(\"title\", \"\")\n",
    "            if title:\n",
    "                # Use first word of title + counter\n",
    "                first_word = re.sub(r'[^\\w]', '', title.split()[0] if title.split() else \"unknown\")\n",
    "                key = f\"ref_{first_word[:20]}_{non_arxiv_counter}\"\n",
    "            else:\n",
    "                key = f\"ref_unknown_{non_arxiv_counter}\"\n",
    "            non_arxiv_counter += 1\n",
    "        \n",
    "        # Extract authors\n",
    "        authors_list = ref.get(\"authors\", [])\n",
    "        authors = [author.get(\"name\", \"\") for author in authors_list if author.get(\"name\")]\n",
    "        \n",
    "        # Extract dates (use publicationDate if available)\n",
    "        publication_date = ref.get(\"publicationDate\", \"\")\n",
    "        year = ref.get(\"year\")\n",
    "        \n",
    "        # Extract corupt ids: corpusId\n",
    "        corpusId = ref.get(\"corpusId\", \"\")\n",
    "        abstract = ref.get(\"abstract\", \"\")\n",
    "        referenceCount = ref.get(\"referenceCount\", \"\")\n",
    "        citationCount = ref.get(\"citationCount\", \"\")\n",
    "        influentialCitationCount = ref.get(\"influentialCitationCount\", \"\")\n",
    "        isOpenAccess = ref.get(\"isOpenAccess\", \"\")\n",
    "        fieldsOfStudy= ref.get(\"fieldsOfStudy\", \"\")\n",
    "        s2FieldsOfStudy = ref.get(\"s2FieldsOfStudy\", [])\n",
    "        publicationTypes = ref.get(\"publicationTypes\", [])\n",
    "        journal = ref.get(\"journal\", \"\")\n",
    "        embedding = ref.get(\"embedding\", [])\n",
    "        \n",
    "        # If no publication date but have year, create an ISO-like format\n",
    "        if not publication_date and year:\n",
    "            publication_date = f\"{year}-01-01\"  # Use Jan 1st as placeholder\n",
    "        \n",
    "        # Build metadata dictionary with required fields\n",
    "        metadata = {\n",
    "            \"title\": ref.get(\"title\", \"\"),\n",
    "            \"authors\": authors,\n",
    "            \"submission_date\": publication_date if publication_date else \"\",\n",
    "            \"revised_dates\": [],  # Semantic Scholar doesn't provide revision history\n",
    "            \"corpusId\" : corpusId,\n",
    "            \"abstract\" : abstract,\n",
    "            \"referenceCount\" : referenceCount,\n",
    "            \"citationCount\" : citationCount,\n",
    "            \"influentialCitationCount\" : influentialCitationCount,\n",
    "            \"isOpenAccess\" : isOpenAccess,\n",
    "            \"fieldsOfStudy\" : fieldsOfStudy,\n",
    "            \"s2FieldsOfStudy\" : s2FieldsOfStudy,\n",
    "            \"publicationTypes\" : publicationTypes,\n",
    "            \"journal\" : journal,\n",
    "            \"embedding\" : embedding,\n",
    "        }\n",
    "        \n",
    "        # Add optional fields for reference\n",
    "        if doi:\n",
    "            metadata[\"doi\"] = doi\n",
    "        if arxiv_id:\n",
    "            metadata[\"arxiv_id\"] = arxiv_id\n",
    "        if ref.get(\"venue\"):\n",
    "            metadata[\"venue\"] = ref.get(\"venue\")\n",
    "        if year:\n",
    "            metadata[\"year\"] = year\n",
    "        \n",
    "        result[key] = metadata\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def save_references(arxiv_id, paper_folder, verbose=True):\n",
    "    \"\"\"\n",
    "    Fetch and save references for a paper version to both JSON and BibTeX formats.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_id: arXiv ID (e.g., \"2304.07856v1\")\n",
    "        version_folder: Path to version folder (e.g., \"data/2304.07856/v1/\")\n",
    "        verbose: Whether to print progress messages\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(paper_folder):\n",
    "        os.makedirs(paper_folder, exist_ok=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Fetching references for {arxiv_id}...\")\n",
    "\n",
    "    references = get_paper_references(arxiv_id)\n",
    "\n",
    "    if not references:\n",
    "        if verbose:\n",
    "            print(f\"  No references found for {arxiv_id}\")\n",
    "        json_path = os.path.join(paper_folder, \"references.json\")\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({}, f, indent=2, ensure_ascii=False)\n",
    "        return False\n",
    "\n",
    "    json_path = os.path.join(paper_folder, \"references.json\")\n",
    "    references_dict = convert_to_references_dict(references)\n",
    "    try:\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(references_dict, f, indent=2, ensure_ascii=False)\n",
    "        if verbose:\n",
    "            print(f\"  Saved {len(references_dict)} references to references.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error saving JSON: {e}\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "def extract_references_for_paper(paper_id, base_data_dir=\"../data\"):\n",
    "    \"\"\"\n",
    "    Extract references for all versions of a paper.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: arXiv paper ID without version (e.g., \"2304.07856\")\n",
    "        base_data_dir: Base directory containing data folders\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistics about the extraction\n",
    "    \"\"\"\n",
    "    paper_id_key = format_yymm_id(paper_id)\n",
    "    paper_folder = os.path.join(base_data_dir, paper_id_key)\n",
    "    if (os.path.exists(paper_folder) == False):\n",
    "        os.makedirs(paper_folder)\n",
    "    save_references(paper_id, os.path.join(paper_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764\n"
     ]
    }
   ],
   "source": [
    "print(len(list_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reference] Starting: 2303.08005\n",
      "[Reference] Starting: 2303.08014\n",
      "Fetching references for 2303.08005...\n",
      "Fetching references for 2303.08014...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...  Rate limit hit. Waiting 2s before retry...\n",
      "\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 13 references to references.json\n",
      "[Reference] Finished: 2303.08005 (Total: 1)\n",
      "[Reference] Starting: 2303.08023\n",
      "Fetching references for 2303.08023...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 27 references to references.json\n",
      "[Reference] Finished: 2303.08014 (Total: 1)\n",
      "[Reference] Starting: 2303.08032\n",
      "Fetching references for 2303.08032...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 42 references to references.json\n",
      "[Reference] Finished: 2303.08032 (Total: 2)\n",
      "[Reference] Starting: 2303.08041\n",
      "Fetching references for 2303.08041...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 24 references to references.json\n",
      "[Reference] Finished: 2303.08023 (Total: 2)\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "[Reference] Starting: 2303.08050\n",
      "Fetching references for 2303.08050...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 3 references to references.json\n",
      "[Reference] Finished: 2303.08041 (Total: 3)\n",
      "[Reference] Starting: 2303.08104\n",
      "Fetching references for 2303.08104...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 27 references to references.json\n",
      "[Reference] Finished: 2303.08050 (Total: 3)\n",
      "[Reference] Starting: 2303.08113\n",
      "Fetching references for 2303.08113...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 26 references to references.json\n",
      "[Reference] Finished: 2303.08113 (Total: 4)\n",
      "[Reference] Starting: 2303.08122\n",
      "Fetching references for 2303.08122...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 8 references to references.json\n",
      "[Reference] Finished: 2303.08122 (Total: 5)\n",
      "[Reference] Starting: 2303.08131\n",
      "Fetching references for 2303.08131...\n",
      "  Saved 18 references to references.json\n",
      "[Reference] Finished: 2303.08104 (Total: 4)\n",
      "  Saved 50 references to references.json\n",
      "[Reference] Finished: 2303.08131 (Total: 6)\n",
      "[Reference] Starting: 2303.08140\n",
      "Fetching references for 2303.08140...\n",
      "[Reference] Starting: 2303.08203\n",
      "Fetching references for 2303.08203...\n",
      "  Saved 38 references to references.json\n",
      "[Reference] Finished: 2303.08140 (Total: 5)\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "[Reference] Starting: 2303.08212\n",
      "Fetching references for 2303.08212...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 2 references to references.json\n",
      "[Reference] Finished: 2303.08212 (Total: 6)\n",
      "  Saved 30 references to references.json\n",
      "[Reference] Finished: 2303.08203 (Total: 7)\n",
      "[Reference] Starting: 2303.08221\n",
      "Fetching references for 2303.08221...\n",
      "[Reference] Starting: 2303.08230\n",
      "Fetching references for 2303.08230...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 10 references to references.json\n",
      "[Reference] Finished: 2303.08230 (Total: 8)\n",
      "[Reference] Starting: 2303.08302\n",
      "Fetching references for 2303.08302...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 32 references to references.json\n",
      "[Reference] Finished: 2303.08302 (Total: 9)\n",
      "[Reference] Starting: 2303.08311\n",
      "Fetching references for 2303.08311...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 6 references to references.json\n",
      "[Reference] Finished: 2303.08311 (Total: 10)\n",
      "[Reference] Starting: 2303.08320\n",
      "Fetching references for 2303.08320...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 46 references to references.json\n",
      "[Reference] Finished: 2303.08320 (Total: 11)\n",
      "  No references found for 2303.08221\n",
      "[Reference] Finished: 2303.08221 (Total: 7)\n",
      "[Reference] Starting: 2303.08401\n",
      "Fetching references for 2303.08401...\n",
      "[Reference] Starting: 2303.08410\n",
      "Fetching references for 2303.08410...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 19 references to references.json\n",
      "[Reference] Finished: 2303.08410 (Total: 8)\n",
      "[Reference] Starting: 2303.08500\n",
      "Fetching references for 2303.08500...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 66 references to references.json\n",
      "[Reference] Finished: 2303.08500 (Total: 9)\n",
      "[Reference] Starting: 2303.09004\n",
      "Fetching references for 2303.09004...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 21 references to references.json\n",
      "[Reference] Finished: 2303.09004 (Total: 10)\n",
      "[Reference] Starting: 2303.09013\n",
      "Fetching references for 2303.09013...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 2 references to references.json\n",
      "[Reference] Finished: 2303.09013 (Total: 11)\n",
      "[Reference] Starting: 2303.09022\n",
      "Fetching references for 2303.09022...\n",
      "  Saved 47 references to references.json\n",
      "[Reference] Finished: 2303.08401 (Total: 12)\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "[Reference] Starting: 2303.09031\n",
      "Fetching references for 2303.09031...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 27 references to references.json\n",
      "[Reference] Finished: 2303.09031 (Total: 13)\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "[Reference] Starting: 2303.09040\n",
      "Fetching references for 2303.09040...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 39 references to references.json\n",
      "[Reference] Finished: 2303.09040 (Total: 14)\n",
      "[Reference] Starting: 2303.09103\n",
      "Fetching references for 2303.09103...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 1 references to references.json\n",
      "[Reference] Finished: 2303.09103 (Total: 15)\n",
      "[Reference] Starting: 2303.09112\n",
      "Fetching references for 2303.09112...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 11 references to references.json\n",
      "[Reference] Finished: 2303.09112 (Total: 16)\n",
      "[Reference] Starting: 2303.09121\n",
      "Fetching references for 2303.09121...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Rate limit hit. Waiting 2s before retry...\n",
      "  Saved 0 references to references.json\n",
      "[Reference] Finished: 2303.09121 (Total: 17)\n",
      "[Reference] Starting: 2303.09130\n",
      "Fetching references for 2303.09130...\n",
      "  Rate limit hit. Waiting 2s before retry...\n"
     ]
    }
   ],
   "source": [
    "def reference_worker(download_queue, base_data_dir, delay=2):\n",
    "    processed = 0\n",
    "    while True:\n",
    "        arxiv_id = download_queue.get()\n",
    "        if arxiv_id is None:\n",
    "            print(f\"[Reference] Thread finished. Total papers processed: {processed}\")\n",
    "            break\n",
    "        try:\n",
    "            print(f\"[Reference] Starting: {arxiv_id}\")\n",
    "            extract_references_for_paper(arxiv_id, base_data_dir)\n",
    "            processed += 1\n",
    "            print(f\"[Reference] Finished: {arxiv_id} (Total: {processed})\")\n",
    "            time.sleep(delay)\n",
    "        except Exception as e:\n",
    "            print(f\"[Reference] Error for {arxiv_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "base_data_dir = \"data\"\n",
    "if os.path.exists(base_data_dir) == False:\n",
    "    os.makedirs(base_data_dir, exist_ok=True)\n",
    "\n",
    "REFERENCE_THREAD_COUNT = 2\n",
    "start_time = time.time()\n",
    "download_queue = queue.Queue()\n",
    "for id in list_id:\n",
    "    download_queue.put(id)\n",
    "\n",
    "\n",
    "reference_threads = []\n",
    "for _ in range(REFERENCE_THREAD_COUNT):\n",
    "    t = threading.Thread(target=reference_worker, args=(download_queue, base_data_dir, 2))\n",
    "    t.start()\n",
    "    reference_threads.append(t)\n",
    "\n",
    "    \n",
    "for t in reference_threads:\n",
    "    t.join()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Pipeline complete. Total time: {end_time - start_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
